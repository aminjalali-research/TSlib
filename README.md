# ğŸš€ TSlib: Comprehensive Time Series Self-Supervised Learning Benchmark

[![Python 3.8+](https://img.shields.io/badge/Python-3.8+-blue.svg)](https://www.python.org/downloads/)
[![PyTorch](https://img.shields.io/badge/PyTorch-1.7+-red.svg)](https://pytorch.org/)
[![License](https://img.shields.io/badge/License-MIT-green.svg)](LICENSE)
[![Enhanced Metrics](https://img.shields.io/badge/Enhanced%20Metrics-Ready-brightgreen.svg)](enhanced_metrics/)

**TSlib** is a unified comprehensive benchmarking framework for time series self-supervised learning models, featuring advanced computational efficiency analysis and real-time GPU monitoring.

## ğŸŒŸ **Key Features**

### **âœ… Comprehensive Model Coverage (25+ Validated Models)**
- **TS2vec Family**: TS2vec, TimeHUT, SoftCLT
- **VQ-MTM Family**: BIOT, VQ_MTM, Ti_MAE, SimMTM, DCRNN
- **MF-CLR Family**: TFC, CoST, CPC, TNC, TS_TCC, TLoss, MF_CLR  
- **TimesURL Family**: TimesURL (98.54% accuracy champion)

### **â­ Enhanced Metrics System (NEW)**
- **ğŸ“… Time/Epoch Analysis**: Average training time per epoch
- **ğŸ”¥ Peak GPU Memory Tracking**: Maximum GPU memory usage monitoring
- **âš¡ FLOPs/Epoch Calculation**: Floating point operations per training epoch
- **ğŸš€ Computational Efficiency**: FLOPs efficiency, Memory efficiency, Time efficiency
- **ğŸ“Š Real-time GPU Monitoring**: Continuous resource tracking during training
- **ğŸ† Performance Champions**: Automatic identification of best performers

### **ğŸ”¬ Scientific Benchmarking**
- **Fair Comparison Mode**: Standardized hyperparameters across all models
- **Cross-Dataset Validation**: UCR and UEA dataset support
- **Statistical Analysis**: Comprehensive performance metrics and efficiency rankings
- **Publication-Ready Results**: Detailed computational analysis for research papers

## ğŸ“Š **Latest Comprehensive Results (Aug 26, 2025)**

### **ğŸ† Performance Champions**

#### **Chinatown Dataset (UCR - Single Channel)**
| Rank | Model | Accuracy | Peak GPU | FLOPs/Epoch | Training Time | Family |
|------|-------|----------|----------|-------------|---------------|---------|
| ğŸ¥‡ | **TimesURL** | **98.54%** | 911MB | 1.13e+08 | 24.3s | TimesURL |
| ğŸ¥ˆ | **SoftCLT** | **97.96%** | 852MB | 5.23e+07 | 7.8s | TS2vec |
| ğŸ¥‰ | **TimeHUT** | **97.38%** | 836MB | 6.03e+07 | 7.8s | TS2vec |

#### **AtrialFibrillation Dataset (UEA - Multi-channel)**
| Rank | Model | Accuracy | Peak GPU | FLOPs/Epoch | Training Time | Family |
|------|-------|----------|----------|-------------|---------------|---------|
| ğŸ¥‡ | **Ti_MAE** | **46.67%** | 2552MB | 1.02e+08 | 7.5s | VQ-MTM |
| ğŸ¥ˆ | **TNC** | **40.00%** | 734MB | 1.02e+10 | 38.2s | MF-CLR |
| ğŸ¥‰ | **TimeHUT** | **33.33%** | 3116MB | 3.40e+07 | 21.0s | TS2vec |

### **âš¡ Efficiency Champions**
- **FLOPs Efficiency**: MF_CLR (11.31 accuracy/GFLOP)
- **Memory Efficiency**: TNC (0.56 accuracy/GB)
- **Speed Champion**: Ti_MAE (7.5s training time)

## ğŸš€ **Quick Start**

### **1. Environment Setup**

```bash
# Clone the repository
git clone https://github.com/aminjalali-research/TSlib.git
cd TSlib

# Create conda environment
conda env create -f environment.yml
conda activate tslib

# Install additional model-specific environments
conda env create -f models/vq_mtm/environment_vq_mtm.yml
conda env create -f models/timesurl/environment_timesurl.yml
```

### **2. Enhanced Metrics Collection (Recommended)**

#### **Single Model Analysis**
```bash
# Champion model with comprehensive metrics
python enhanced_metrics/enhanced_single_model_runner.py TimesURL Chinatown 120

# Efficiency analysis
python enhanced_metrics/enhanced_single_model_runner.py Ti_MAE AtrialFibrillation 180
python enhanced_metrics/enhanced_single_model_runner.py MF_CLR AtrialFibrillation 60
```

#### **Batch Model Comparison**
```bash
# Compare top performers across datasets
python enhanced_metrics/enhanced_batch_runner.py --models TimesURL,Ti_MAE,TimeHUT --datasets Chinatown,AtrialFibrillation --timeout 200

# Comprehensive family analysis
python enhanced_metrics/enhanced_batch_runner.py --models TS2vec,TimeHUT,SoftCLT --datasets Chinatown --timeout 120
```

### **3. Basic Benchmarking**
```bash
# Traditional benchmarking (basic metrics)
python unified/master_benchmark_pipeline.py --models TimesURL --datasets Chinatown --optimization --timeout 120
```

## ğŸ“ **Repository Structure**

```
TSlib/
â”œâ”€â”€ ğŸ”¥ enhanced_metrics/           # â­ Primary analysis system
â”‚   â”œâ”€â”€ enhanced_single_model_runner.py    # Individual model analysis  
â”‚   â”œâ”€â”€ enhanced_batch_runner.py           # Batch processing
â”‚   â”œâ”€â”€ demo.py                            # System demonstration
â”‚   â”œâ”€â”€ results/                           # Individual results
â”‚   â””â”€â”€ batch_results/                     # Batch analysis summaries
â”œâ”€â”€ ğŸ“Š core/                       # Core TSlib functionality
â”‚   â”œâ”€â”€ backbone.py                # Model architectures
â”‚   â”œâ”€â”€ losses.py                  # Loss functions
â”‚   â”œâ”€â”€ train.py                   # Training pipeline
â”‚   â””â”€â”€ unified_dataset_reader.py  # Dataset handling
â”œâ”€â”€ ğŸ¤– models/                     # Model implementations (working models only)
â”‚   â”œâ”€â”€ timesurl/                  # 98.54% accuracy champion
â”‚   â”œâ”€â”€ ts2vec/                    # Universal performer family
â”‚   â”œâ”€â”€ timehut/                   # Cross-dataset consistency
â”‚   â”œâ”€â”€ softclt/                   # UCR specialist
â”‚   â””â”€â”€ vq_mtm/                    # VQ-MTM model family
â”œâ”€â”€ ğŸ”§ unified/                    # Unified benchmarking system
â”‚   â”œâ”€â”€ master_benchmark_pipeline.py      # Main pipeline
â”‚   â”œâ”€â”€ TaskGuide.md                      # Complete usage guide
â”‚   â””â”€â”€ consolidated_metrics_interface.py # Legacy metrics interface
â”œâ”€â”€ ğŸ“ˆ results/                    # Comprehensive results
â”‚   â”œâ”€â”€ COMPLETE_RESULTS_SUMMARY.csv      # All model results
â”‚   â”œâ”€â”€ comprehensive_model_comparison_metrics.json
â”‚   â””â”€â”€ comprehensive_metrics/             # Detailed analyses
â”œâ”€â”€ âš™ï¸ setup/                      # Environment and data setup
â”‚   â”œâ”€â”€ setup.sh                  # Main setup script  
â”‚   â”œâ”€â”€ download_datasets.sh      # Dataset download
â”‚   â””â”€â”€ run_gpu.sh                 # GPU execution helper
â”œâ”€â”€ ğŸ“‹ environment.yml             # Main conda environment
â”œâ”€â”€ ğŸ“– unified/TaskGuide.md        # Complete usage documentation
â””â”€â”€ ğŸ¯ PROJECT_COMPLETION_SUMMARY.md      # Project status
```

## ğŸ† **Model Performance Overview**

### **Working Models (25 Total Experiments)**
- âœ… **100% Success Rate**: All 25 model-dataset combinations completed successfully
- âœ… **Single Epoch Training**: Fair comparison across all architectures  
- âœ… **Comprehensive Metrics**: Time/Epoch, Peak GPU Memory, FLOPs/Epoch for all models
- âœ… **Cross-Dataset Validation**: Both UCR and UEA dataset types tested

### **Model Families**
1. **TS2vec Family (3 models)**: Best overall performers, excellent accuracy-efficiency trade-off
2. **VQ-MTM Family (5 models)**: Specialized for complex multivariate datasets
3. **MF-CLR Family (7 models)**: Computational efficiency leaders
4. **TimesURL (1 model)**: Accuracy champion with complex architecture

## ğŸ”¬ **Enhanced Metrics Capabilities**

### **Computational Analysis**
- **FLOPs Estimation**: Architecture-based computational complexity analysis
- **Memory Profiling**: Peak and average GPU memory usage tracking
- **Efficiency Metrics**: Accuracy per GFLOP, accuracy per GB, time efficiency
- **Energy Estimation**: Sustainability analysis with kWh consumption estimates

### **Performance Intelligence**
- **Champion Identification**: Automatic detection of best performers across metrics
- **Family Comparison**: Statistical analysis by model architecture families
- **Resource Optimization**: Identify computational bottlenecks and improvements
- **Production Planning**: Resource requirement assessment for deployment

## ğŸ“– **Documentation**

- **[Complete TaskGuide](unified/TaskGuide.md)**: Comprehensive usage instructions with all working commands
- **[Project Summary](PROJECT_COMPLETION_SUMMARY.md)**: Development history and achievements
- **[Enhanced Metrics README](enhanced_metrics/README.md)**: Detailed enhanced metrics documentation

## ğŸ¯ **Use Cases**

### **Research Applications**
- **Scientific Benchmarking**: Publication-ready computational complexity analysis
- **Model Selection**: Data-driven choice based on accuracy-efficiency trade-offs
- **Architecture Analysis**: Deep understanding of computational characteristics
- **Cross-Dataset Validation**: Robust model evaluation across dataset types

### **Production Applications**
- **Resource Planning**: GPU memory and computation requirements assessment  
- **Deployment Optimization**: Efficiency-based model selection for production
- **Cost Analysis**: Energy consumption and computational cost evaluation
- **Performance Monitoring**: Real-time resource usage tracking

## âš¡ **Key Achievements**

- ğŸ† **98.54% Accuracy**: TimesURL achieving state-of-the-art performance on Chinatown
- ğŸ“Š **25 Successful Experiments**: Complete validation across all working models
- âš¡ **11.31 acc/GFLOP**: MF_CLR achieving highest computational efficiency
- ğŸ”¥ **Real-time Monitoring**: Advanced GPU resource tracking during training
- ğŸ“ˆ **Single-Epoch Discovery**: Fair computational comparison methodology
- ğŸš€ **Enhanced Metrics System**: Comprehensive computational analysis beyond accuracy

## ğŸ¤ **Contributing**

We welcome contributions! Please see our contribution guidelines and feel free to:
- Add new time series SSL models
- Improve computational efficiency analysis
- Extend dataset support
- Enhance visualization capabilities

## ğŸ“„ **License**

This project is licensed under the MIT License - see the [LICENSE](LICENSE) file for details.

## ğŸ”— **Citation**

If you use TSlib in your research, please cite:

```bibtex
@misc{tslib2025,
  title={TSlib: Comprehensive Time Series Self-Supervised Learning Benchmark with Enhanced Computational Analysis},
  author={Amin Jalali Research Lab},
  year={2025},
  howpublished={\\url{https://github.com/aminjalali-research/TSlib}}
}
```

## ğŸ“ **Contact**

For questions, issues, or collaboration opportunities, please:
- Open an issue on GitHub
- Contact: aminjalali-research

---

â­ **Star this repository if you find TSlib useful for your time series research!**
